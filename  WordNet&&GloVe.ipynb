{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfTSdFNat3syfMK8nyPJu4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheUnifyingForce/Taxonomy-of-Multi-Modal-Datasets/blob/main/%20WordNet%26%26GloVe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WordNet\n",
        "\n",
        "#### A large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms (synsets), each expressing a distinct concept. Synsets are interlinked by means of conceptual-semantic and lexical relations.\n",
        "\n",
        "#### WordNet superficially resembles a thesaurus, in that it groups words together based on their meanings. However, there are some important distinctions.\n",
        "\n",
        "\n",
        "*   First, WordNet interlinks not just word forms—strings of letters—but specific senses of words. As a result, words that are found in close proximity to one another in the network are semantically disambiguated.\n",
        "*   Second, WordNet labels the semantic relations among words, whereas the groupings of words in a thesaurus does not follow any explicit pattern other than meaning similarity.\n",
        "\n"
      ],
      "metadata": {
        "id": "9TCr3Sb0vuBL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2iOd6rJtVa1",
        "outputId": "d5ed8be0-a9cd-40ff-d4d2-010d3fc8fc7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPeekOlKtire",
        "outputId": "d14fc3f6-aabe-4554-b91a-68fd9f740cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet"
      ],
      "metadata": {
        "id": "p-dvTMQdtkGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# synonyms sets\n",
        "synsets_image = wordnet.synsets('image')\n",
        "print(synsets_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ry4f2WstoIg",
        "outputId": "89dafb86-83dd-493c-bb47-35fc2b3d30f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('image.n.01'), Synset('persona.n.02'), Synset('picture.n.01'), Synset('prototype.n.01'), Synset('trope.n.01'), Synset('double.n.03'), Synset('image.n.07'), Synset('image.n.08'), Synset('effigy.n.01'), Synset('image.v.01'), Synset('visualize.v.01')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# definition\n",
        "synset_image = wordnet.synset('image.n.03')\n",
        "print(synset_image.definition())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjerL3sztoxQ",
        "outputId": "c53a2357-f3b9-4165-d1b2-dcbcb2cfbaa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a visual representation (of an object or scene or person or abstraction) produced on a surface\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# synonyms sets\n",
        "synsets_painting = wordnet.synsets('painting')\n",
        "print(synsets_painting)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmUcbXq44Gcs",
        "outputId": "16e64cc8-2d0c-481f-8e13-e26781804aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('painting.n.01'), Synset('painting.n.02'), Synset('painting.n.03'), Synset('painting.n.04'), Synset('paint.v.01'), Synset('paint.v.02'), Synset('paint.v.03'), Synset('paint.v.04')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# definition\n",
        "synset_painting = wordnet.synset('painting.n.01')\n",
        "print(synset_painting.definition())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr_YqO7h4x69",
        "outputId": "0cbb7121-4b56-454f-c05f-2b2a149bca10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "graphic art consisting of an artistic composition made by applying paints to a surface\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all formats\n",
        "lemmas = synset_image.lemmas()\n",
        "for lemma in lemmas:\n",
        "    print(lemma.name())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-meBZqbtyy-",
        "outputId": "90b3f89d-c5b0-4c30-bff7-0717c1200fd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "picture\n",
            "image\n",
            "icon\n",
            "ikon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hypernyms\n",
        "hypernyms = synset_image.hypernyms()\n",
        "print(hypernyms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6TxUkUQtynv",
        "outputId": "172d3a40-d232-4281-8e4f-94621ef04d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('representation.n.02')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hypernyms\n",
        "hypernyms = synset_painting.hypernyms()\n",
        "print(hypernyms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr2OoYsz5Hz7",
        "outputId": "3e264d98-c8a9-445e-8264-2be3a7e65fef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('graphic_art.n.01')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypernyms = wordnet.synset('entity.n.01').hypernyms()\n",
        "print(hypernyms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_wPLcjV4BQt",
        "outputId": "1e99be18-e6a6-4a6c-f1fa-6cfc7a4098fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyponyms\n",
        "hyponyms = synset_image.hyponyms()\n",
        "print(hyponyms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PazC7BbbuLy8",
        "outputId": "a32dd353-99db-4e77-bfd0-f2b137b48fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('bitmap.n.01'), Synset('chiaroscuro.n.01'), Synset('collage.n.01'), Synset('foil.n.04'), Synset('graphic.n.01'), Synset('iconography.n.01'), Synset('inset.n.01'), Synset('likeness.n.02'), Synset('panorama.n.02'), Synset('reflection.n.05'), Synset('scan.n.02'), Synset('sonogram.n.01')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyponyms\n",
        "hyponyms = synset_painting.hyponyms()\n",
        "print(hyponyms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6DO-FoC5Iz7",
        "outputId": "06b8f4f2-f906-4f17-90af-a7a781056dbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('abstraction.n.04'), Synset('cityscape.n.02'), Synset('daub.n.03'), Synset('distemper.n.04'), Synset('finger-painting.n.01'), Synset('icon.n.03'), Synset('landscape.n.02'), Synset('miniature.n.01'), Synset('monochrome.n.01'), Synset('mural.n.01'), Synset('nude.n.01'), Synset('oil_painting.n.01'), Synset('pentimento.n.01'), Synset('sand_painting.n.01'), Synset('seascape.n.02'), Synset('semi-abstraction.n.01'), Synset('still_life.n.01'), Synset('tanka.n.02'), Synset('trompe_l'oeil.n.01'), Synset('watercolor.n.01')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GloVe\n",
        "\n",
        "#### https://nlp.stanford.edu/pubs/glove.pdf\n",
        "#### http://nlp.stanford.edu/projects/glove/\n",
        "#### A global log-bilinear regression model for the unsupervised learning of word representations that outperforms other models on word analogy, word similarity, and named entity recognition tasks."
      ],
      "metadata": {
        "id": "NxYxS-0xvth6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors"
      ],
      "metadata": {
        "id": "2kWQsahMwlJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2_6Y46bxCWM",
        "outputId": "3ac35d2c-c1ad-4471-d264-8c749396d4e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-25 14:45:26--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2024-04-25 14:45:26--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-04-25 14:45:26--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.11MB/s    in 2m 40s  \n",
            "\n",
            "2024-04-25 14:48:07 (5.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYQU3re43ybG",
        "outputId": "1e947508-c4ad-4490-f349-fe9602b7f1e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "glove_model = KeyedVectors.load_word2vec_format('glove.6B.300d.txt', binary=False, no_header=True)"
      ],
      "metadata": {
        "id": "hbL7NdQRxLMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the vector representation of a word\n",
        "vector = glove_model['image']\n",
        "print(vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNIzyNsoxOdO",
        "outputId": "89aa2df8-f0d9-4716-d774-9c09516520cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.0065397  0.12888   -0.12518   -0.48984   -0.15711   -0.21177\n",
            " -0.24202    0.58976    0.36224   -1.8508     0.63151    0.085513\n",
            "  0.54285   -0.085016  -0.37762   -0.069195   0.29284   -0.4923\n",
            " -0.32498   -0.78226   -0.41842    0.46761    0.7178     0.077404\n",
            " -0.18717   -0.27108   -0.41315   -0.18285    0.7223     0.88308\n",
            "  0.17942    0.087     -0.20642    0.37093   -0.78857    0.65427\n",
            "  0.16744   -0.56659    0.055369  -0.071142   0.31651    0.1864\n",
            "  0.24052   -0.12697   -0.44088   -0.37085   -0.078073  -0.49468\n",
            "  0.11863   -0.20714    0.15563   -0.3569     0.71721   -0.13097\n",
            "  0.28312    0.0065318 -0.2072     0.24517    0.064092  -0.013316\n",
            " -0.024133   0.25595    0.071349  -0.13245    0.33029    0.38863\n",
            " -0.31963   -0.60819    0.76155    0.30382   -0.13193   -0.18959\n",
            "  0.37761   -0.023783   0.26459   -0.7078     0.08579    0.017591\n",
            " -0.038224   0.12083   -1.0479    -0.015986  -0.45525   -0.40214\n",
            " -0.070824   0.3338    -0.50845    0.043117   0.081949  -0.091315\n",
            " -0.64257    0.10965   -0.24919   -0.094988  -0.090982  -0.36591\n",
            "  0.076012  -0.17875    0.33409   -0.87304   -0.20569    0.05255\n",
            "  0.041013   0.13646   -0.29788    0.47942   -0.089447   0.064284\n",
            " -0.019177  -0.22885    0.24997    0.20244    0.21037   -0.37881\n",
            "  0.18943   -0.35137    0.26105    0.18101   -0.3914    -0.49769\n",
            "  0.2898     0.31548    0.10525    0.16974   -0.16078    0.16469\n",
            " -0.059585   0.54874    0.12506    0.058332  -0.0039565  0.20828\n",
            "  0.45704    0.7798    -0.14028   -0.083668   0.23792    0.041788\n",
            "  0.36119    0.22773   -0.28982   -0.16743   -0.47954    0.3603\n",
            "  0.26597   -0.62985    0.41955    0.10149    0.046858  -0.1164\n",
            "  0.39186   -0.034736   0.2134    -0.020998   0.054348   0.065916\n",
            " -0.076614  -0.17096    0.54265    0.22073   -0.13178   -0.20812\n",
            "  0.026737   0.0047888  0.57398   -0.4316    -0.22518    0.16313\n",
            " -0.13481   -0.17169    0.097558  -0.1236    -0.63796   -0.38537\n",
            " -0.13056   -0.22697    0.21242   -0.0037222 -0.051278  -0.35677\n",
            " -0.53311    0.1716     0.30364    0.42892   -0.33112   -0.58286\n",
            "  0.69547   -0.1813    -0.063949   0.012561  -0.47068    0.4255\n",
            " -0.57865    0.72422   -0.22248    0.12841    0.26521   -0.2045\n",
            " -0.034962   0.11698    1.5236    -0.22641    0.4708     0.18476\n",
            "  0.054965  -0.61467   -0.2486     0.44132   -0.42538    0.33672\n",
            "  0.19796    0.42917   -0.29999    0.13624    0.38837    0.32961\n",
            "  0.39121   -0.72204   -0.13437    0.79517   -0.71789    0.50715\n",
            "  0.2371     0.090043   0.084823  -0.22617    0.046514   0.080781\n",
            "  0.067446   0.040738  -0.024774   0.084163   0.024366  -0.43004\n",
            " -0.036371  -0.32674    0.16242   -0.22003   -0.41027   -0.19339\n",
            "  0.031136   0.05953   -0.29085   -0.1102    -0.74596   -0.49905\n",
            " -0.25229   -0.30203   -0.51611    0.13506    0.16106   -0.34322\n",
            "  0.060467  -0.05831    0.2933     0.15908   -0.15369   -0.024627\n",
            "  0.33084   -0.35545    0.09745    0.4561    -0.021635   0.7468\n",
            "  0.026807  -0.0026561 -0.24848    0.079938   0.42847   -0.084578\n",
            " -0.16758    0.0054878  0.41982   -0.15215   -0.42941    0.42962\n",
            " -0.98876   -0.31169    0.83858   -0.10118   -0.26155   -0.19292\n",
            " -0.55513    0.058276   0.26274    0.29613   -0.1923     0.47476\n",
            "  0.17916    0.24851    0.54397    0.14452   -0.43562   -0.058503\n",
            "  0.075884   0.0088287  0.38792   -0.0022971 -0.17996   -0.30759  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the semantic similarity between words\n",
        "similarity = glove_model.similarity('image', 'picture')\n",
        "print(similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idRI4UdoxQZt",
        "outputId": "4ca71062-5959-4720-8475-51643c2d4971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5823847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the word that is most similar to the given word.\n",
        "similar_words = glove_model.most_similar('image')\n",
        "print(similar_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYMlWHd8xSKW",
        "outputId": "fcc63c23-0bf3-46b0-a020-e3edf9a4a40a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('images', 0.6631151437759399), ('picture', 0.5823846459388733), ('reputation', 0.5361216068267822), ('tarnished', 0.5312350988388062), ('photograph', 0.5112592577934265), ('photo', 0.49377116560935974), ('perception', 0.48240020871162415), ('look', 0.47880640625953674), ('color', 0.46893924474716187), ('pictures', 0.4675300419330597)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Solve the analogy problem in vocabulary (such as king - man + woman = queen)\n",
        "analogy = glove_model.most_similar(positive=['king', 'woman'], negative=['man'])\n",
        "print(analogy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCBNZdxuxUDg",
        "outputId": "e75c4033-dd96-406e-8c4b-1a1c67ce8088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('queen', 0.6713277101516724), ('princess', 0.5432624816894531), ('throne', 0.5386103987693787), ('monarch', 0.5347574949264526), ('daughter', 0.49802514910697937), ('mother', 0.49564430117607117), ('elizabeth', 0.4832652509212494), ('kingdom', 0.47747090458869934), ('prince', 0.4668239951133728), ('wife', 0.46473270654678345)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply\n",
        "\n",
        "\n",
        "1.   Get Datatypes from some paragraph\n",
        "2.   Classify?\n",
        "\n",
        "     (1) Check if it's exsist, if not go to step 2, if yes mark down the linkage of the dataset\n",
        "\n",
        "     (2) Sementic classify: put the new data type in a big genre (image, audio, text etc) first\n",
        "\n",
        "     (3) Calculate word relations of this new\n",
        "3.   \n",
        "\n"
      ],
      "metadata": {
        "id": "FKLEdyGpDymx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the SpaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_nouns(text):\n",
        "    # Process the text with SpaCy\n",
        "    doc = nlp(text)\n",
        "    # Extract nouns from the processed document\n",
        "    nouns = [token.text for token in doc if token.pos_ == \"NOUN\"]\n",
        "    return nouns"
      ],
      "metadata": {
        "id": "ACGDGkR5ElwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example paragraph\n",
        "paragraph = \"WikiArt contains painting from 195 different artists. The dataset has 42129 images for training and 10628 images for testing.\"\n",
        "\n",
        "# Extract nouns from the paragraph\n",
        "nouns = extract_nouns(paragraph)\n",
        "print(\"Nouns in the paragraph:\", nouns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6gw7Qr1EwXl",
        "outputId": "a0b782d2-e025-4896-91a5-d14de8a7df70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nouns in the paragraph: ['artists', 'dataset', 'images', 'training', 'images', 'testing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_data_types(description):\n",
        "    # Process the description with SpaCy\n",
        "    doc = nlp(description)\n",
        "\n",
        "    # Initialize a set to store unique data types\n",
        "    data_types = set()\n",
        "\n",
        "    # Iterate over tokens in the processed document\n",
        "    for token in doc:\n",
        "        # Check if the token is a noun and add it to the set of data types\n",
        "        if token.pos_ == \"NOUN\":\n",
        "            data_types.add(token.text.lower())  # Convert to lowercase for consistency\n",
        "\n",
        "    return data_types\n",
        "\n",
        "# Example dataset description\n",
        "description = \"WikiArt contains painting from 195 different artists. The dataset has 42129 images for training and 10628 images for testing.\"\n",
        "\n",
        "# Extract data types from the description\n",
        "data_types = extract_data_types(description)\n",
        "print(\"Data types in the description:\", data_types)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKI-oxv9FKZz",
        "outputId": "325bab61-7fae-432b-b4b3-02c9a8086198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data types in the description: {'images', 'training', 'dataset', 'artists', 'testing'}\n"
          ]
        }
      ]
    }
  ]
}