{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize an empty list to store data for each row\n",
        "rows = []\n",
        "\n",
        "# Read the JSONL file line by line\n",
        "with open(\"combined_results_2.jsonl\", \"r\") as file:\n",
        "    for line in file:\n",
        "        try:\n",
        "            # Parse the JSON data from each line\n",
        "            item = json.loads(line.strip())\n",
        "\n",
        "            # Extract dataset_name and dataset_description\n",
        "            dataset_name = item.get(\"input\", {}).get(\"dataset_name\", \"Unknown\")\n",
        "            dataset_description = item.get(\"input\", {}).get(\"dataset_description\", \"Unknown\")\n",
        "\n",
        "            # Extract all titles from the modalities in the output\n",
        "            modalities = item.get(\"output\", \"\")\n",
        "            if modalities.startswith(\"```json\"):  # Remove formatting markers in the JSON string\n",
        "                modalities = modalities.strip(\"```json\\n\").strip(\"```\")\n",
        "            modalities_data = json.loads(modalities)  # Parse the string as JSON\n",
        "\n",
        "            # Collect all titles\n",
        "            titles = []\n",
        "            for modality in modalities_data.get(\"modalities\", []):\n",
        "                titles.append(modality.get(\"title\", \"Unknown\"))\n",
        "\n",
        "            # Add data to the row\n",
        "            rows.append({\n",
        "                \"dataset_name\": dataset_name,\n",
        "                \"dataset_description\": dataset_description,\n",
        "                \"modalities_titles\": \", \".join(titles)  # Join titles with a comma separator\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing entry, skipping this line: {line}, Error: {e}\")\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "# Save as a CSV file\n",
        "df.to_csv(\"output_jiewen.csv\", index=False)\n",
        "print(\"Data has been successfully saved to output_jiewen.csv!\")"
      ],
      "metadata": {
        "id": "mlhY5SM7bDrW",
        "outputId": "2f27b07a-ce64-4f07-80b5-f8cd2876dbc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry, skipping this line: {\"custom_id\": \"task-4818\", \"input\": {\"dataset_name\": \"Helix\", \"dataset_description\": \"See https://zenodo.org/record/5500215#.YUCgD51Kg2w\"}, \"output\": \"I'm unable to access external content such as the specific dataset description from Zenodo. However, I can provide a general structure for a multimodal dataset based on common modalities and data types. If you have specific details about the \\\"Helix\\\" dataset, please provide them, and I can tailor the response accordingly.\\n\\n```json\\n{\\n    \\\"modalities\\\": [\\n        {\\n            \\\"title\\\": \\\"text\\\",\\n            \\\"explanation\\\": \\\"This modality includes any textual data that might be part of the dataset.\\\",\\n            \\\"data_types\\\": [\\n                {\\n                    \\\"title\\\": \\\"description\\\",\\n                    \\\"explanation\\\": \\\"Textual descriptions or annotations related to the dataset.\\\"\\n                }\\n            ]\\n        },\\n        {\\n            \\\"title\\\": \\\"image\\\",\\n            \\\"explanation\\\": \\\"This modality includes any visual data in the form of images.\\\",\\n            \\\"data_types\\\": [\\n                {\\n                    \\\"title\\\": \\\"scientific imagery\\\",\\n                    \\\"explanation\\\": \\\"Images related to scientific data or visualizations.\\\"\\n                }\\n            ]\\n        },\\n        {\\n            \\\"title\\\": \\\"audio\\\",\\n            \\\"explanation\\\": \\\"This modality includes any auditory data that might be part of the dataset.\\\",\\n            \\\"data_types\\\": [\\n                {\\n                    \\\"title\\\": \\\"recordings\\\",\\n                    \\\"explanation\\\": \\\"Audio recordings that may be relevant to the dataset.\\\"\\n                }\\n            ]\\n        }\\n    ]\\n}\\n```\\n\\nPlease provide more specific information if available, and I can refine the response further.\"}\n",
            ", Error: Expecting value: line 1 column 1 (char 0)\n",
            "Error processing entry, skipping this line: {\"custom_id\": \"task-6036\", \"input\": {\"dataset_name\": \"https://osf.io/73c4q/\", \"dataset_description\": \"Briganti et al. 2018\"}, \"output\": \"I'm sorry, but I can't access external links or specific datasets directly. However, if you provide a description or details about the dataset, I can help identify potential modalities and data types that might be included.\"}\n",
            ", Error: Expecting value: line 1 column 1 (char 0)\n",
            "Error processing entry, skipping this line: {\"custom_id\": \"task-6037\", \"input\": {\"dataset_name\": \"https://osf.io/mj5wa/\", \"dataset_description\": \"Armour et al. 2017\"}, \"output\": \"I'm sorry, but I cannot access external links or specific datasets directly. However, if you provide a description or details about the dataset, I can help identify potential modalities and data types that might be included.\"}\n",
            ", Error: Expecting value: line 1 column 1 (char 0)\n",
            "Error processing entry, skipping this line: {\"custom_id\": \"task-6785\", \"input\": {\"dataset_name\": \"RECON\", \"dataset_description\": \"https://sites.google.com/view/recon-robot/dataset\"}, \"output\": \"I'm sorry, but I can't access external websites or specific dataset descriptions. However, I can help you identify potential modalities and data types that might be included in a dataset named \\\"RECON,\\\" which could be related to robotics or similar fields. Here's a general example of how such a dataset might be structured:\\n\\n```json\\n{\\n    \\\"modalities\\\": [\\n        {\\n            \\\"title\\\": \\\"image\\\",\\n            \\\"explanation\\\": \\\"Visual data captured by cameras or sensors.\\\",\\n            \\\"data_types\\\": [\\n                {\\n                    \\\"title\\\": \\\"robotic_environment_images\\\",\\n                    \\\"explanation\\\": \\\"Images depicting the environment in which robots operate.\\\"\\n                },\\n                {\\n                    \\\"title\\\": \\\"robot_components_images\\\",\\n                    \\\"explanation\\\": \\\"Images of various components or parts of robots.\\\"\\n                }\\n            ]\\n        },\\n        {\\n            \\\"title\\\": \\\"video\\\",\\n            \\\"explanation\\\": \\\"Motion data capturing sequences of actions or events.\\\",\\n            \\\"data_types\\\": [\\n                {\\n                    \\\"title\\\": \\\"robot_operations_video\\\",\\n                    \\\"explanation\\\": \\\"Videos showing robots performing tasks or operations.\\\"\\n                }\\n            ]\\n        },\\n        {\\n            \\\"title\\\": \\\"text\\\",\\n            \\\"explanation\\\": \\\"Written data providing descriptions or annotations.\\\",\\n            \\\"data_types\\\": [\\n                {\\n                    \\\"title\\\": \\\"operation_instructions\\\",\\n                    \\\"explanation\\\": \\\"Textual instructions or guidelines for robot operations.\\\"\\n                },\\n                {\\n                    \\\"title\\\": \\\"environment_descriptions\\\",\\n                    \\\"explanation\\\": \\\"Textual descriptions of the environments where robots are deployed.\\\"\\n                }\\n            ]\\n        },\\n        {\\n            \\\"title\\\": \\\"audio\\\",\\n            \\\"explanation\\\": \\\"Sound data captured from the environment or robots.\\\",\\n            \\\"data_types\\\": [\\n                {\\n                    \\\"title\\\": \\\"environmental_sounds\\\",\\n                    \\\"explanation\\\": \\\"Audio recordings of sounds in the robot's environment.\\\"\\n                }\\n            ]\\n        }\\n    ]\\n}\\n```\\n\\nThis is a hypothetical example and may not accurately reflect the actual contents of the \\\"RECON\\\" dataset. If you have more specific information about the dataset, I can provide a more tailored response.\"}\n",
            ", Error: Expecting value: line 1 column 1 (char 0)\n",
            "Error processing entry, skipping this line: {\"custom_id\": \"task-8880\", \"input\": {\"dataset_name\": \"CARE\", \"dataset_description\": \"https://drive.google.com/file/d/1X_JTfD8Ch-IxmG5VHtKk_xGZT336Fl1Q/view?usp=drive_link\"}, \"output\": \"I'm sorry, but I can't access external links or specific datasets directly. However, I can help you identify potential modalities and data types that might be included in a dataset named \\\"CARE\\\" based on common practices. Here's a general example:\\n\\n```json\\n{\\n    \\\"modalities\\\": [\\n        {\\n            \\\"title\\\": \\\"text\\\",\\n            \\\"explanation\\\": \\\"This modality includes any textual information that might be part of the dataset.\\\",\\n            \\\"data_types\\\": [\\n                {\\n                    \\\"title\\\": \\\"medical reports\\\",\\n                    \\\"explanation\\\": \\\"Textual data containing medical observations, diagnoses, and treatment plans.\\\"\\n                },\\n                {\\n                    \\\"title\\\": \\\"patient feedback\\\",\\n                    \\\"explanation\\\": \\\"Textual data capturing patient experiences and feedback.\\\"\\n                }\\n            ]\\n        },\\n        {\\n            \\\"title\\\": \\\"image\\\",\\n            \\\"explanation\\\": \\\"This modality includes any visual data that might be part of the dataset.\\\",\\n            \\\"data_types\\\": [\\n                {\\n                    \\\"title\\\": \\\"x-ray images\\\",\\n                    \\\"explanation\\\": \\\"Images capturing x-ray scans of patients.\\\"\\n                },\\n                {\\n                    \\\"title\\\": \\\"MRI scans\\\",\\n                    \\\"explanation\\\": \\\"Images capturing MRI scans for medical analysis.\\\"\\n                }\\n            ]\\n        },\\n        {\\n            \\\"title\\\": \\\"audio\\\",\\n            \\\"explanation\\\": \\\"This modality includes any auditory data that might be part of the dataset.\\\",\\n            \\\"data_types\\\": [\\n                {\\n                    \\\"title\\\": \\\"doctor-patient conversations\\\",\\n                    \\\"explanation\\\": \\\"Audio recordings of conversations between doctors and patients.\\\"\\n                }\\n            ]\\n        }\\n    ]\\n}\\n```\\n\\nPlease adjust the modalities and data types based on the actual content of the \\\"CARE\\\" dataset if you have more specific information.\"}\n",
            ", Error: Expecting value: line 1 column 1 (char 0)\n",
            "Error processing entry, skipping this line: {\"custom_id\": \"task-9045\", \"input\": {\"dataset_name\": \"BikeDNA Denmark Analysis\", \"dataset_description\": \"See https://zenodo.org/records/10185500\"}, \"output\": \"I'm sorry, but I can't access external content such as the link you provided. However, I can help you identify potential modalities and data types based on the dataset name \\\"BikeDNA Denmark Analysis.\\\" Here's a possible structure:\\n\\n```json\\n{\\n    \\\"modalities\\\": [\\n        {\\n            \\\"title\\\": \\\"text\\\",\\n            \\\"explanation\\\": \\\"This modality may include textual data related to the analysis of bike usage in Denmark.\\\",\\n            \\\"data_types\\\": [\\n                {\\n                    \\\"title\\\": \\\"reports\\\",\\n                    \\\"explanation\\\": \\\"Textual reports or summaries of bike usage analysis.\\\"\\n                },\\n                {\\n                    \\\"title\\\": \\\"metadata\\\",\\n                    \\\"explanation\\\": \\\"Textual metadata describing the dataset or individual data entries.\\\"\\n                }\\n            ]\\n        },\\n        {\\n            \\\"title\\\": \\\"image\\\",\\n            \\\"explanation\\\": \\\"This modality may include images related to bike usage or infrastructure in Denmark.\\\",\\n            \\\"data_types\\\": [\\n                {\\n                    \\\"title\\\": \\\"bike_infrastructure\\\",\\n                    \\\"explanation\\\": \\\"Images depicting bike lanes, parking, or other infrastructure.\\\"\\n                },\\n                {\\n                    \\\"title\\\": \\\"biking_activity\\\",\\n                    \\\"explanation\\\": \\\"Images capturing biking activities or events.\\\"\\n                }\\n            ]\\n        },\\n        {\\n            \\\"title\\\": \\\"geospatial\\\",\\n            \\\"explanation\\\": \\\"This modality may include geospatial data related to bike routes or locations in Denmark.\\\",\\n            \\\"data_types\\\": [\\n                {\\n                    \\\"title\\\": \\\"bike_routes\\\",\\n                    \\\"explanation\\\": \\\"Geospatial data representing bike routes or paths.\\\"\\n                },\\n                {\\n                    \\\"title\\\": \\\"location_data\\\",\\n                    \\\"explanation\\\": \\\"Geospatial data indicating specific locations of interest.\\\"\\n                }\\n            ]\\n        }\\n    ]\\n}\\n```\\n\\nThis is a hypothetical structure based on the dataset name. If you have more specific information about the dataset, I can refine the tags further.\"}\n",
            ", Error: Expecting value: line 1 column 1 (char 0)\n",
            "Data has been successfully saved to output_jiewen.csv!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize an empty list to store results\n",
        "rows = []\n",
        "\n",
        "# Open the JSON file\n",
        "with open(\"results.json\", \"r\") as file:\n",
        "    try:\n",
        "        # Load JSON data\n",
        "        data = json.load(file)\n",
        "\n",
        "        # Extract information\n",
        "        for item in data:\n",
        "            # Get the name and keep only the part before the parentheses\n",
        "            name = item.get(\"name\", \"Unknown\").split(\" (\")[0]\n",
        "\n",
        "            # Get the titles under modalities in tags\n",
        "            modalities = item.get(\"tags\", {}).get(\"modalities\", [])\n",
        "            modality_titles = [modality.get(\"title\", \"Unknown\") for modality in modalities]\n",
        "\n",
        "            # Add data to rows\n",
        "            rows.append({\n",
        "                \"name\": name,\n",
        "                \"modalities_titles\": \", \".join(modality_titles)  # Join titles with commas\n",
        "            })\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSON format error: {e}. Please check the file content!\")\n",
        "\n",
        "# Create a DataFrame\n",
        "if rows:\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    # Save as a CSV file\n",
        "    df.to_csv(\"output_yu.csv\", index=False)\n",
        "    print(\"DataFrame has been successfully saved to output_yu.csv\")\n",
        "else:\n",
        "    print(\"No data was generated. The file might be empty or all entries have issues.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHdMeg-rhPg0",
        "outputId": "9b264491-6a7d-44e1-fd0b-16f6f1090f39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame has been successfully saved to output_yu.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read two CSV files\n",
        "output_jiewen = pd.read_csv(\"output_jiewen.csv\")\n",
        "output_yu = pd.read_csv(\"output_yu.csv\")\n",
        "\n",
        "# Extract the common column and ensure consistent name handling\n",
        "output_jiewen[\"dataset_name\"] = output_jiewen[\"dataset_name\"]\n",
        "output_yu[\"name\"] = output_yu[\"name\"]\n",
        "\n",
        "# Merge the two files based on the common column (name or dataset_name)\n",
        "merged_df = pd.merge(\n",
        "    output_jiewen.rename(columns={\"dataset_name\": \"name\"}),\n",
        "    output_yu,\n",
        "    on=\"name\",\n",
        "    how=\"inner\",  # Keep only the common rows\n",
        "    suffixes=(\"_jiewen\", \"_yu\")  # Avoid column name conflicts\n",
        ")\n",
        "\n",
        "# Rearrange and rename columns\n",
        "final_df = merged_df[[\"name\", \"dataset_description\", \"modalities_titles_jiewen\", \"modalities_titles_yu\"]]\n",
        "final_df.columns = [\"name\", \"dataset_description\", \"modalities_jiewen\", \"modalities_yu\"]\n",
        "\n",
        "# Save the final result to a new CSV file\n",
        "final_df.to_csv(\"merged_output.csv\", index=False)\n",
        "print(\"The merged file has been successfully saved as merged_output.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "De4US8FmuHcO",
        "outputId": "8285388d-bdd0-42ce-a2ab-5a8e686d544e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The merged file has been successfully saved as merged_output.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the file\n",
        "file_path = \"merged_output.csv\"  # Replace with your file path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Print the number of rows in the file\n",
        "print(f\"The total number of rows in the file is: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaM8Qbo7u2l6",
        "outputId": "622a01a8-fd3b-4650-f040-7c039999713e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of rows in the file is: 10224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the number of rows where the third and fourth columns are the same\n",
        "same_count = (df.iloc[:, 2] == df.iloc[:, 3]).sum()\n",
        "\n",
        "# Print the result\n",
        "print(f\"The number of rows where the third and fourth columns are the same is: {same_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZ9dkHY3vLJJ",
        "outputId": "c468e1e9-3cec-49a9-e344-0ee5960f0217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of rows where the third and fourth columns are the same is: 6252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "different_rows_df = df[df.iloc[:, 2] != df.iloc[:, 3]]"
      ],
      "metadata": {
        "id": "v3Evo8fFvlg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly sample 20 rows from the DataFrame while keeping the result reproducible by setting random_state\n",
        "sample_df = different_rows_df.sample(n=20, random_state=42)\n",
        "print(sample_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RNaqWCo0Goz",
        "outputId": "af0d2e0d-75cd-4614-c0b8-602ae9e3b738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   name  \\\n",
            "7371                                               ATUE   \n",
            "3252                           twitter politicians data   \n",
            "6279                                           AnoShift   \n",
            "3219  NISP- A Multi-lingual Multi-accent Dataset for...   \n",
            "7457                                       MO-Gymnasium   \n",
            "6233  Replication Data for: The use of differential ...   \n",
            "7446                                PACE 2022 Heuristic   \n",
            "7065                                          Wild-Time   \n",
            "8567  3D-Point Cloud dataset of various geometrical ...   \n",
            "4136                        Dark Machines Anomaly Score   \n",
            "8139                                       TriMouse-161   \n",
            "8193                                         DeepPatent   \n",
            "1991                                                H3D   \n",
            "3470                                           TCR-pMHC   \n",
            "9385                          Student-Teacher Prompting   \n",
            "5470                          Simulated EM showers data   \n",
            "2658                                          SoccerNet   \n",
            "9002                                             CaBuAr   \n",
            "7352                                               MTTN   \n",
            "944                             Freiburg Across Seasons   \n",
            "\n",
            "                                    dataset_description  \\\n",
            "7371  **ATUE** is an antibody study benchmark with f...   \n",
            "3252  Dataset based on Twitter usernames of American...   \n",
            "6279  AnoShift is a large-scale anomaly detection be...   \n",
            "3219  We announce the release of a new multilingual ...   \n",
            "7457  MO-Gymnasium is an open source Python library ...   \n",
            "6233  Census statistics play a key role in public po...   \n",
            "7446  This is the set of graphs used in the [PACE 20...   \n",
            "7065  **Wild-Time** is a benchmark of 5 datasets tha...   \n",
            "8567  Depth vision has been recently used in many lo...   \n",
            "4136  This dataset is the outcome of a data challeng...   \n",
            "8139  Three wild-type (C57BL/6J) male mice ran on a ...   \n",
            "8193  The dataset consists of over 350,000 public do...   \n",
            "1991  The H3D is a large scale full-surround 3D mult...   \n",
            "3470  10x Genomics dataset of sequenced TCRs barcode...   \n",
            "9385  **Student-Teacher Prompting** is an instructio...   \n",
            "5470  Electromagnetic (EM) showers simulated dataset...   \n",
            "2658  A benchmark for action spotting in soccer vide...   \n",
            "9002  This dataset contains images from Sentinel-2 s...   \n",
            "7352  **MTTN** is a large scale derived and synthesi...   \n",
            "944   **Freiburg Across Seasons** captures long-term...   \n",
            "\n",
            "                               modalities_jiewen  \\\n",
            "7371                       text, biological_data   \n",
            "3252                                        text   \n",
            "6279                                        text   \n",
            "3219                                 audio, text   \n",
            "7457                               text, numeric   \n",
            "6233                               text, tabular   \n",
            "7446                                        text   \n",
            "7065                                 text, image   \n",
            "8567                              3D Point Cloud   \n",
            "4136                             text, numerical   \n",
            "8139                                 image, text   \n",
            "8193                                       image   \n",
            "1991                 3D Point Cloud, Annotations   \n",
            "3470                               text, genomic   \n",
            "9385  text, image, gesture, physical interaction   \n",
            "5470                                        text   \n",
            "2658                                 video, text   \n",
            "9002                                 image, text   \n",
            "7352                                        text   \n",
            "944                                  image, text   \n",
            "\n",
            "                        modalities_yu  \n",
            "7371            text, biological data  \n",
            "3252                 text, identifier  \n",
            "6279            text, network traffic  \n",
            "3219           audio, text, numerical  \n",
            "7457              numerical, software  \n",
            "6233                  text, numerical  \n",
            "7446                      graph, text  \n",
            "7065                             text  \n",
            "8567              3D data, Depth data  \n",
            "4136            simulation, numerical  \n",
            "8139                     image, video  \n",
            "8193                      image, text  \n",
            "1991         3D data, Annotation data  \n",
            "3470                 genomic, barcode  \n",
            "9385  text, gesture, visual, physical  \n",
            "5470           numerical, categorical  \n",
            "2658       video, text, temporal data  \n",
            "9002                      image, mask  \n",
            "7352                      text, image  \n",
            "944                   image, location  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly select 20 rows\n",
        "sample_df = different_rows_df.sample(n=20, random_state=42)  # Ensure reproducibility by setting random_state\n",
        "\n",
        "# Merge the third and fourth columns, remove duplicates, and combine them into a string\n",
        "def merge_and_deduplicate(row):\n",
        "    col3 = row.iloc[2].split(\",\")  # Split the third column by commas\n",
        "    col4 = row.iloc[3].split(\",\")  # Split the fourth column by commas\n",
        "    merged = list(set(col3 + col4))  # Merge the two lists and remove duplicates\n",
        "    return \",\".join(merged)  # Combine the list into a single string\n",
        "\n",
        "# Add a new column to store the merged result\n",
        "sample_df[\"merged_columns\"] = sample_df.apply(merge_and_deduplicate, axis=1)\n",
        "\n",
        "# Keep the name, description, and merged result\n",
        "result_df = sample_df[[\"name\", \"dataset_description\"]].copy()  # Assuming name and description columns exist\n",
        "result_df[\"merged_columns\"] = sample_df[\"merged_columns\"]\n",
        "\n",
        "# Print the processed result\n",
        "print(result_df)\n",
        "\n",
        "# Save to a file if needed\n",
        "output_path = \"sampled_different_rows_with_metadata.csv\"\n",
        "result_df.to_csv(output_path, index=False)\n",
        "print(f\"The result has been saved to {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipBjjcwKvnwo",
        "outputId": "4f5768cf-0d34-4d63-a330-2573c387b46f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   name  \\\n",
            "7371                                               ATUE   \n",
            "3252                           twitter politicians data   \n",
            "6279                                           AnoShift   \n",
            "3219  NISP- A Multi-lingual Multi-accent Dataset for...   \n",
            "7457                                       MO-Gymnasium   \n",
            "6233  Replication Data for: The use of differential ...   \n",
            "7446                                PACE 2022 Heuristic   \n",
            "7065                                          Wild-Time   \n",
            "8567  3D-Point Cloud dataset of various geometrical ...   \n",
            "4136                        Dark Machines Anomaly Score   \n",
            "8139                                       TriMouse-161   \n",
            "8193                                         DeepPatent   \n",
            "1991                                                H3D   \n",
            "3470                                           TCR-pMHC   \n",
            "9385                          Student-Teacher Prompting   \n",
            "5470                          Simulated EM showers data   \n",
            "2658                                          SoccerNet   \n",
            "9002                                             CaBuAr   \n",
            "7352                                               MTTN   \n",
            "944                             Freiburg Across Seasons   \n",
            "\n",
            "                                    dataset_description  \\\n",
            "7371  **ATUE** is an antibody study benchmark with f...   \n",
            "3252  Dataset based on Twitter usernames of American...   \n",
            "6279  AnoShift is a large-scale anomaly detection be...   \n",
            "3219  We announce the release of a new multilingual ...   \n",
            "7457  MO-Gymnasium is an open source Python library ...   \n",
            "6233  Census statistics play a key role in public po...   \n",
            "7446  This is the set of graphs used in the [PACE 20...   \n",
            "7065  **Wild-Time** is a benchmark of 5 datasets tha...   \n",
            "8567  Depth vision has been recently used in many lo...   \n",
            "4136  This dataset is the outcome of a data challeng...   \n",
            "8139  Three wild-type (C57BL/6J) male mice ran on a ...   \n",
            "8193  The dataset consists of over 350,000 public do...   \n",
            "1991  The H3D is a large scale full-surround 3D mult...   \n",
            "3470  10x Genomics dataset of sequenced TCRs barcode...   \n",
            "9385  **Student-Teacher Prompting** is an instructio...   \n",
            "5470  Electromagnetic (EM) showers simulated dataset...   \n",
            "2658  A benchmark for action spotting in soccer vide...   \n",
            "9002  This dataset contains images from Sentinel-2 s...   \n",
            "7352  **MTTN** is a large scale derived and synthesi...   \n",
            "944   **Freiburg Across Seasons** captures long-term...   \n",
            "\n",
            "                                         merged_columns  \n",
            "7371              biological_data, biological data,text  \n",
            "3252                                    identifier,text  \n",
            "6279                               network traffic,text  \n",
            "3219                             audio, text, numerical  \n",
            "7457                  numerical, numeric, software,text  \n",
            "6233                            numerical, tabular,text  \n",
            "7446                                   graph, text,text  \n",
            "7065                                         image,text  \n",
            "8567                  Depth data,3D data,3D Point Cloud  \n",
            "4136                          numerical,simulation,text  \n",
            "8139                                  video,image, text  \n",
            "8193                                        image, text  \n",
            "1991   Annotation data,3D data, Annotations,3D Point...  \n",
            "3470                      genomic, barcode,genomic,text  \n",
            "9385   image, physical interaction,text, visual, phy...  \n",
            "5470                        numerical, categorical,text  \n",
            "2658                         video, text, temporal data  \n",
            "9002                                   mask,image, text  \n",
            "7352                                         image,text  \n",
            "944                               image, text, location  \n",
            "结果已保存到 sampled_different_rows_with_metadata.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read verification_data.csv\n",
        "verification_df = pd.read_csv('verification_data.csv')\n",
        "\n",
        "# Merge sample_df and verification_df based on the 'name' column\n",
        "merged_df = pd.merge(sample_df, verification_df, on='name', how='inner')\n",
        "\n",
        "# Define a function to split words (supporting both comma and space as delimiters)\n",
        "def split_words(text):\n",
        "    if pd.isna(text):  # Handle missing values\n",
        "        return set()\n",
        "    # Replace commas with spaces and split by spaces\n",
        "    return set(text.replace(',', ' ').split())\n",
        "\n",
        "# Initialize counters\n",
        "total_jiewen_words = set()\n",
        "total_yu_words = set()\n",
        "total_verification_words = set()\n",
        "\n",
        "# Iterate through each row and collect all words\n",
        "for _, row in merged_df.iterrows():\n",
        "    total_jiewen_words.update(split_words(row['modalities_jiewen']))\n",
        "    total_yu_words.update(split_words(row['modalities_yu']))\n",
        "    total_verification_words.update(split_words(row['Verification']))\n",
        "\n",
        "# Calculate jiewen_percentage\n",
        "common_jiewen_words = total_verification_words.intersection(total_jiewen_words)\n",
        "if len(total_jiewen_words) == 0:\n",
        "    jiewen_percentage = 0\n",
        "else:\n",
        "    jiewen_percentage = len(common_jiewen_words) / len(total_jiewen_words)\n",
        "\n",
        "# Calculate yu_percentage\n",
        "common_yu_words = total_verification_words.intersection(total_yu_words)\n",
        "if len(total_yu_words) == 0:\n",
        "    yu_percentage = 0\n",
        "else:\n",
        "    yu_percentage = len(common_yu_words) / len(total_yu_words)\n",
        "\n",
        "# Output the results\n",
        "print(f\"jiewen_percentage: {jiewen_percentage:.2%}\")\n",
        "print(f\"yu_percentage: {yu_percentage:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiALEOU--7U4",
        "outputId": "f678742b-be94-43e3-ba96-acc696ce89e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jiewen_percentage: 81.25%\n",
            "yu_percentage: 60.00%\n"
          ]
        }
      ]
    }
  ]
}