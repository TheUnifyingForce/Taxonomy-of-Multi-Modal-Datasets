# Taxonomy-of-Multi-Modal-Datasets
Master Project_UZH

## Kick-off
The goal of this Master project is to develope a systematic framework to extract semantic relationships between modalities (e.g., images, text) and their associated data types (e.g., JPEG, CSV) from the information of dataset metadata. By constructing a knowledge graph that formalizes these relationships, we aim to enable structured taxonomy and efficient search capabilities for multimodal dataset.

## **Repository Structure**  
- ðŸ“‚ **01 Dataset Selection** â€“ Chapter 2
- ðŸ“‚ **02 Model Selection** â€“ Chapter 3
- ðŸ“‚ **03 Data Types Extraction** â€“ Chapter 4
- ðŸ“‚ **04 Normalization of Multimodal Data Representation** â€“ Chapter 5
- ðŸ“‚ **05 Knowledge Graph Construction** â€“ Chapter 7
- ðŸ“œ **README.md** â€“ Project documentation  

## Usage
Run relevant notebooks or scripts in each folder as needed.  