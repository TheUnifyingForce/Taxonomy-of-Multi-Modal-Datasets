{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c92e57ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e53a7c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Data/PaperWithCode/tmp_z9_dir9'\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "780b5fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10197"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72e633e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "      \"url\":         str\n",
      "      \"name\":         str\n",
      "      \"full_name\":         str\n",
      "      \"homepage\":         str\n",
      "      \"description\":         str\n",
      "      \"paper\":         {\n",
      "          \"title\":             str\n",
      "          \"url\":             str\n",
      "        }\n",
      "      \"introduced_date\":         str\n",
      "      \"warning\":         NoneType\n",
      "      \"modalities\":         [\n",
      "            str\n",
      "        ]\n",
      "      \"tasks\":         [\n",
      "            {\n",
      "              \"task\":                 str\n",
      "              \"url\":                 str\n",
      "            }\n",
      "        ]\n",
      "      \"languages\":         [\n",
      "        ]\n",
      "      \"variants\":         [\n",
      "            str\n",
      "        ]\n",
      "      \"num_papers\":         int\n",
      "      \"data_loaders\":         [\n",
      "            {\n",
      "              \"url\":                 str\n",
      "              \"repo\":                 str\n",
      "              \"frameworks\":                 [\n",
      "                    str\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "def get_json_structure(data, indent=0):\n",
    "    indent_str = ' ' * indent\n",
    "    if isinstance(data, dict):\n",
    "        print(f\"{indent_str}{{\")\n",
    "        for key, value in data.items():\n",
    "            print(f\"{indent_str}  \\\"{key}\\\": \", end=\"\")\n",
    "            get_json_structure(value, indent + 4)\n",
    "        print(f\"{indent_str}}}\")\n",
    "    \n",
    "    elif isinstance(data, list):\n",
    "        print(f\"{indent_str}[\")\n",
    "        if data:\n",
    "            # Only analyze the first element in the list to determine structure\n",
    "            get_json_structure(data[0], indent + 4)\n",
    "        print(f\"{indent_str}]\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"{indent_str}{type(data).__name__}\")\n",
    "\n",
    "# Get the structure of JSON\n",
    "get_json_structure(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c58713d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ijson\n",
      "  Downloading ijson-3.3.0-cp310-cp310-macosx_11_0_arm64.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ijson\n",
      "Successfully installed ijson-3.3.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Frameworks/Python.framework/Versions/3.10/bin/python3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install ijson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d63473a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"url\": \"https://paperswithcode.com/dataset/mnist\",\n",
      "    \"name\": \"MNIST\",\n",
      "    \"full_name\": \"\",\n",
      "    \"homepage\": \"http://yann.lecun.com/exdb/mnist/\",\n",
      "    \"description\": \"The **MNIST** database (**Modified National Institute of Standards and Technology** database) is a large collection of handwritten digits. It has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger NIST Special Database 3 (digits written by employees of the United States Census Bureau) and Special Database 1 (digits written by high school students) which contain monochrome images of handwritten digits. The digits have been size-normalized and centered in a fixed-size image. The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.\\r\\n\\r\\nSource: [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)\\r\\nImage Source: [https://en.wikipedia.org/wiki/MNIST_database#/media/File:MnistExamples.png](https://en.wikipedia.org/wiki/MNIST_database#/media/File:MnistExamples.png)\",\n",
      "    \"paper\": {\n",
      "        \"title\": \"Gradient-based learning applied to document recognition\",\n",
      "        \"url\": \"https://paperswithcode.com/paper/gradient-based-learning-applied-to-document\"\n",
      "    },\n",
      "    \"introduced_date\": \"1998-11-01\",\n",
      "    \"warning\": null,\n",
      "    \"modalities\": [\n",
      "        \"Images\"\n",
      "    ],\n",
      "    \"tasks\": [\n",
      "        {\n",
      "            \"task\": \"Image Classification\",\n",
      "            \"url\": \"https://paperswithcode.com/task/image-classification\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Speech Recognition\",\n",
      "            \"url\": \"https://paperswithcode.com/task/speech-recognition\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Question Answering\",\n",
      "            \"url\": \"https://paperswithcode.com/task/question-answering\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Image Generation\",\n",
      "            \"url\": \"https://paperswithcode.com/task/image-generation\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Text Classification\",\n",
      "            \"url\": \"https://paperswithcode.com/task/text-classification\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Domain Adaptation\",\n",
      "            \"url\": \"https://paperswithcode.com/task/domain-adaptation\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Anomaly Detection\",\n",
      "            \"url\": \"https://paperswithcode.com/task/anomaly-detection\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Graph Classification\",\n",
      "            \"url\": \"https://paperswithcode.com/task/graph-classification\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Continual Learning\",\n",
      "            \"url\": \"https://paperswithcode.com/task/continual-learning\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Image Clustering\",\n",
      "            \"url\": \"https://paperswithcode.com/task/image-clustering\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Fine-Grained Image Classification\",\n",
      "            \"url\": \"https://paperswithcode.com/task/fine-grained-image-classification\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Neural Architecture Search\",\n",
      "            \"url\": \"https://paperswithcode.com/task/architecture-search\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Video Prediction\",\n",
      "            \"url\": \"https://paperswithcode.com/task/video-prediction\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Unsupervised Anomaly Detection\",\n",
      "            \"url\": \"https://paperswithcode.com/task/unsupervised-anomaly-detection\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Density Estimation\",\n",
      "            \"url\": \"https://paperswithcode.com/task/density-estimation\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Core set discovery\",\n",
      "            \"url\": \"https://paperswithcode.com/task/core-set-discovery\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Clustering Algorithms Evaluation\",\n",
      "            \"url\": \"https://paperswithcode.com/task/clustering-algorithms-evaluation\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Adversarial Defense\",\n",
      "            \"url\": \"https://paperswithcode.com/task/adversarial-defense\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Stochastic Optimization\",\n",
      "            \"url\": \"https://paperswithcode.com/task/stochastic-optimization\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"General Classification\",\n",
      "            \"url\": \"https://paperswithcode.com/task/classification\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Token Classification\",\n",
      "            \"url\": \"https://paperswithcode.com/task/token-classification\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Summarization\",\n",
      "            \"url\": \"https://paperswithcode.com/task/summarization\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Unsupervised Image Classification\",\n",
      "            \"url\": \"https://paperswithcode.com/task/unsupervised-image-classification\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Personalized Federated Learning\",\n",
      "            \"url\": \"https://paperswithcode.com/task/personalized-federated-learning\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Multiview Clustering\",\n",
      "            \"url\": \"https://paperswithcode.com/task/multiview-clustering\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Network Pruning\",\n",
      "            \"url\": \"https://paperswithcode.com/task/network-pruning\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Deep Clustering\",\n",
      "            \"url\": \"https://paperswithcode.com/task/deep-clustering\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Unsupervised Anomaly Detection with Specified Settings -- 30% anomaly\",\n",
      "            \"url\": \"https://paperswithcode.com/task/unsupervised-anomaly-detection-with-specified\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Unsupervised Anomaly Detection with Specified Settings -- 20% anomaly\",\n",
      "            \"url\": \"https://paperswithcode.com/task/unsupervised-anomaly-detection-with-specified-4\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Unsupervised Anomaly Detection with Specified Settings -- 1% anomaly\",\n",
      "            \"url\": \"https://paperswithcode.com/task/unsupervised-anomaly-detection-with-specified-5\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Unsupervised Anomaly Detection with Specified Settings -- 0.1% anomaly\",\n",
      "            \"url\": \"https://paperswithcode.com/task/unsupervised-anomaly-detection-with-specified-6\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Unsupervised Anomaly Detection with Specified Settings -- 10% anomaly\",\n",
      "            \"url\": \"https://paperswithcode.com/task/unsupervised-anomaly-detection-with-specified-7\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Intent Classification\",\n",
      "            \"url\": \"https://paperswithcode.com/task/intent-classification\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"NER\",\n",
      "            \"url\": \"https://paperswithcode.com/task/cg\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Sequential Image Classification\",\n",
      "            \"url\": \"https://paperswithcode.com/task/sequential-image-classification\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Continuously Indexed Domain Adaptation\",\n",
      "            \"url\": \"https://paperswithcode.com/task/continuously-indexed-domain-adaptation\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Classification with Binary Weight Network\",\n",
      "            \"url\": \"https://paperswithcode.com/task/classification-with-binary-weight-network\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"POS\",\n",
      "            \"url\": \"https://paperswithcode.com/task/pos\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Model Poisoning\",\n",
      "            \"url\": \"https://paperswithcode.com/task/model-poisoning\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Sparse Learning and binarization\",\n",
      "            \"url\": \"https://paperswithcode.com/task/sparse-learning-and-binarization\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Unsupervised Image-To-Image Translation\",\n",
      "            \"url\": \"https://paperswithcode.com/task/unsupervised-image-to-image-translation\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Hard-label Attack\",\n",
      "            \"url\": \"https://paperswithcode.com/task/hard-label-attack\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Nature-Inspired Optimization Algorithm\",\n",
      "            \"url\": \"https://paperswithcode.com/task/nature-inspired-optimization-algorithm\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Structured Prediction\",\n",
      "            \"url\": \"https://paperswithcode.com/task/structured-prediction\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"One-Shot Learning\",\n",
      "            \"url\": \"https://paperswithcode.com/task/one-shot-learning\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Handwritten Digit Recognition\",\n",
      "            \"url\": \"https://paperswithcode.com/task/handwritten-digit-recognition\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Unsupervised MNIST\",\n",
      "            \"url\": \"https://paperswithcode.com/task/unsupervised-mnist\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Rotated MNIST\",\n",
      "            \"url\": \"https://paperswithcode.com/task/rotated-mnist\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Superpixel Image Classification\",\n",
      "            \"url\": \"https://paperswithcode.com/task/superpixel-image-classification\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"TAG\",\n",
      "            \"url\": \"https://paperswithcode.com/task/tag\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Multi Label Text Classification\",\n",
      "            \"url\": \"https://paperswithcode.com/task/multi-label-text-classification-1\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Malicious Detection\",\n",
      "            \"url\": \"https://paperswithcode.com/task/malicious-detection\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Adversarial Defense against FGSM Attack\",\n",
      "            \"url\": \"https://paperswithcode.com/task/adversarial-defense-against-fgsm-attack\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Iloko Speech Recognition\",\n",
      "            \"url\": \"https://paperswithcode.com/task/iloko-speech-recognition\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"WOLOF Speech Recognition\",\n",
      "            \"url\": \"https://paperswithcode.com/task/wolof-speech-recognition\"\n",
      "        }\n",
      "    ],\n",
      "    \"languages\": [],\n",
      "    \"variants\": [\n",
      "        \"USPS-to-MNIST\",\n",
      "        \"MNIST-to-USPS\",\n",
      "        \"Rotating MNIST\",\n",
      "        \"Noisy MNIST (Motion)\",\n",
      "        \"Noisy MNIST (Contrast)\",\n",
      "        \"Noisy MNIST (AWGN)\",\n",
      "        \"MNIST (Conditional)\",\n",
      "        \"Indexed Rotating MNIST\",\n",
      "        \"Rotated MNIST\",\n",
      "        \"Moving MNIST\",\n",
      "        \"Sequential MNIST\",\n",
      "        \"SVNH-to-MNIST\",\n",
      "        \"MNIST-test\",\n",
      "        \"MNIST-full\",\n",
      "        \"MNIST\",\n",
      "        \"75 Superpixel MNIST\"\n",
      "    ],\n",
      "    \"num_papers\": 7114,\n",
      "    \"data_loaders\": [\n",
      "        {\n",
      "            \"url\": \"https://huggingface.co/datasets/ylecun/mnist\",\n",
      "            \"repo\": \"https://github.com/huggingface/datasets\",\n",
      "            \"frameworks\": [\n",
      "                \"tf\",\n",
      "                \"pytorch\",\n",
      "                \"jax\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"url\": \"https://huggingface.co/datasets/mnist\",\n",
      "            \"repo\": \"https://github.com/huggingface/datasets\",\n",
      "            \"frameworks\": [\n",
      "                \"tf\",\n",
      "                \"pytorch\",\n",
      "                \"jax\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"url\": \"https://huggingface.co/datasets/filwsyl/video_understanding\",\n",
      "            \"repo\": \"https://github.com/huggingface/datasets\",\n",
      "            \"frameworks\": [\n",
      "                \"tf\",\n",
      "                \"pytorch\",\n",
      "                \"jax\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"url\": \"https://huggingface.co/datasets/filwsyl/video_tags\",\n",
      "            \"repo\": \"https://github.com/huggingface/datasets\",\n",
      "            \"frameworks\": [\n",
      "                \"tf\",\n",
      "                \"pytorch\",\n",
      "                \"jax\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"url\": \"https://huggingface.co/datasets/severo/mnist\",\n",
      "            \"repo\": \"https://github.com/huggingface/datasets\",\n",
      "            \"frameworks\": [\n",
      "                \"tf\",\n",
      "                \"pytorch\",\n",
      "                \"jax\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"url\": \"https://huggingface.co/datasets/mqddb/test-dataset\",\n",
      "            \"repo\": \"https://github.com/huggingface/datasets\",\n",
      "            \"frameworks\": [\n",
      "                \"tf\",\n",
      "                \"pytorch\",\n",
      "                \"jax\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"url\": \"https://huggingface.co/datasets/asoria/mnist\",\n",
      "            \"repo\": \"https://github.com/huggingface/datasets\",\n",
      "            \"frameworks\": [\n",
      "                \"tf\",\n",
      "                \"pytorch\",\n",
      "                \"jax\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"url\": \"https://huggingface.co/datasets/renumics/mnist-outlier\",\n",
      "            \"repo\": \"https://github.com/huggingface/datasets\",\n",
      "            \"frameworks\": [\n",
      "                \"tf\",\n",
      "                \"pytorch\",\n",
      "                \"jax\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"url\": \"https://huggingface.co/datasets/sc890/deepfruit_dataset\",\n",
      "            \"repo\": \"https://github.com/huggingface/datasets\",\n",
      "            \"frameworks\": [\n",
      "                \"tf\",\n",
      "                \"pytorch\",\n",
      "                \"jax\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"url\": \"https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html\",\n",
      "            \"repo\": \"https://github.com/pytorch/vision\",\n",
      "            \"frameworks\": [\n",
      "                \"pytorch\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"url\": \"https://docs.voxel51.com/user_guide/dataset_zoo/datasets.html#mnist\",\n",
      "            \"repo\": \"https://github.com/voxel51/fiftyone\",\n",
      "            \"frameworks\": [\n",
      "                \"tf\",\n",
      "                \"pytorch\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"url\": \"https://docs.activeloop.ai/datasets/mnist\",\n",
      "            \"repo\": \"https://github.com/activeloopai/Hub\",\n",
      "            \"frameworks\": [\n",
      "                \"tf\",\n",
      "                \"pytorch\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"url\": \"https://www.tensorflow.org/datasets/catalog/mnist\",\n",
      "            \"repo\": \"https://github.com/tensorflow/datasets\",\n",
      "            \"frameworks\": [\n",
      "                \"tf\",\n",
      "                \"jax\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"url\": \"https://github.com/open-mmlab/mmclassification/blob/master/docs/getting_started.md\",\n",
      "            \"repo\": \"https://github.com/open-mmlab/mmclassification\",\n",
      "            \"frameworks\": [\n",
      "                \"pytorch\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"url\": \"https://graphneural.network/datasets/#mnist\",\n",
      "            \"repo\": \"https://github.com/danielegrattarola/spektral\",\n",
      "            \"frameworks\": [\n",
      "                \"tf\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"url\": \"https://gas.graviti.com/dataset/hellodataset/MNIST\",\n",
      "            \"repo\": \"https://github.com/Graviti-AI/datasets\",\n",
      "            \"frameworks\": [\n",
      "                \"tf\",\n",
      "                \"pytorch\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"url\": \"https://gitlab.com/afagarap/pt-datasets\",\n",
      "            \"repo\": \"https://gitlab.com/afagarap/pt-datasets\",\n",
      "            \"frameworks\": [\n",
      "                \"pytorch\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import ijson\n",
    "import json\n",
    "\n",
    "def print_first_entry(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Initialize the parser to read items from the array\n",
    "        parser = ijson.items(file, 'item')\n",
    "        \n",
    "        # Get the first item from the parser\n",
    "        first_item = next(parser, None)\n",
    "        \n",
    "        if first_item:\n",
    "            # Pretty-print the first item\n",
    "            print(json.dumps(first_item, indent=4))\n",
    "        else:\n",
    "            print(\"No items found in the JSON file.\")\n",
    "\n",
    "# print the first entry\n",
    "print_first_entry(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea035ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
